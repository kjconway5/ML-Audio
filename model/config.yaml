# Configuration for 3-Class Keyword Spotting (yes, silence, unknown)
# Based on Google Speech Commands dataset

# Dataset paths and settings
dataset:
  data_dir: "/workspace/model/data/speech_commands_v0.02"
  
data:
  output_dir: "/workspace/model/output"
  
  #
  classes:
    - "no"
    - "yes"
    - "stop"
    - "go"
    - "happy"
 #   - "silence"
    - "unknown"
  
  # Target keywords to detect (everything else becomes "unknown")
  target_keywords:
    - "no"
    - "yes"
    - "stop"
    - "go"
    - "happy"

  # Silence generation (from background noise)
  include_silence: false
  num_silence_samples: 1000

  # Cap on "unknown" examples per split (null for no cap)
  unknown_max_per_split: 4000

  # Reproducibility
  random_seed: 42

# Preprocessing settings
preprocessing:
  sample_rate: 16000
  n_mels: 40        # Number of mel frequency bins
  n_fft: 512        # FFT size
  hop_length: 160   # 10ms hop at 16kHz
  window_length: 512
  
  # Filters (if using)
  use_filters: false
  hpf_order: 2
  lpf_order: 4
  cutoff_hpf: 150
  cutoff_lpf: 4000

# Model architecture
model:
  n_classes: 6  # no, yes, stop, go, happy, unknown
  
  # First convolution layer
  first_conv:
    filters: 64
    kernel_size: [10, 4]
    stride: [2, 2]
  
  # Depthwise Separable blocks
  ds_blocks:
    n_blocks: 4
    filters: 64
    kernel_size: [3, 3]
    stride: [1, 1]

# Training settings
training:
  n_epochs: 200
  batch_size: 64
  
  # Optimizer: SGD with momentum
  optimizer: "sgd"
  learning_rate: 0.1
  momentum: 0.9
  weight_decay: 0.0001
  
  # Learning rate schedule: decay by 0.1 at epochs 5, 10, 15
  lr_schedule:
    milestones: [5, 10, 15]
    gamma: 0.1
  
  # Validation schedule
  val_every: 5  # Validate at epochs 5, 10, 15, 20

# Output settings
output:
  model_save_path: "model_final.pt"
  log_file: "training_log.txt"